{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch \n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "from typing import List, Callable, Union, Any, TypeVar, Tuple\n",
    "Tensor = TypeVar('torch.tensor')\n",
    "\n",
    "import torch.optim as optim\n",
    "\n",
    "\n",
    "# Data preprocessing utils : \n",
    "from utils.acdc_dataset import ACDC_Dataset, One_hot_Transform, load_dataset\n",
    "from torchvision.transforms import Compose\n",
    "from torchvision import transforms\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "# Visuals utils\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "# my defined model\n",
    "from utils.vqVAE import VQVAE\n",
    "from utils.training import *\n",
    "\n",
    "# from matplotlib.colors import ListedColormap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "L = 128 # image size L=W\n",
    "BATCH_SIZE = 16\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = \"/home/ids/ihamdaoui-21/ACDC/database\"\n",
    "\n",
    "train_set_path = os.path.join(dataset_path, \"training\")\n",
    "test_set_path  = os.path.join(dataset_path, \"testing\")\n",
    "\n",
    "test_dataset  = load_dataset(test_set_path)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_transforms = Compose([\n",
    "    transforms.Resize(size=(L,L), interpolation=transforms.InterpolationMode.NEAREST),\n",
    "    One_hot_Transform(num_classes=4)\n",
    "    ])\n",
    "\n",
    "\n",
    "TestDataset  = ACDC_Dataset(data = test_dataset, transforms= input_transforms)\n",
    "\n",
    "TestLoader   = DataLoader(TestDataset , batch_size = BATCH_SIZE, shuffle = True)\n",
    "\n",
    "in_channels = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# detect gpu ?\n",
    "\n",
    "print(torch.cuda.is_available())\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "vis_batch = next(iter(TestLoader)).to(device)\n",
    "visualize_batch(vis_batch.detach().cpu(), title= \"grount truth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------\n",
    "## Test Model 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = 'saved_models/vqvae_100_bestmodel.pth'\n",
    "\n",
    "model = VQVAE(in_channels, 64, 512)\n",
    "model.load_state_dict(torch.load(model_path)['model_state_dict'])\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_hat = reconstruct_logits(vis_batch, model)\n",
    "probs = F.softmax(batch_hat, dim=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize_batch_logits( batch_hat.detach().cpu() , title= \"model100 predictions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize_batch( probs.detach().cpu() , title= \"model100 predictions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_seg = torch.argmax(probs,     dim=1).detach().cpu()\n",
    "true_seg = torch.argmax(vis_batch, dim=1).detach().cpu()\n",
    "\n",
    "visualize_errors(true_seg, pred_seg, 'Prediction errors visualization')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_Dice_score = evaluate_model(model, TestLoader, dice_score, device)\n",
    "print(model_Dice_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------\n",
    "# Test Model 101"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = 'saved_models/vqvae_101_bestmodel.pth'\n",
    "\n",
    "model = VQVAE(in_channels, 64, 512)\n",
    "model.load_state_dict(torch.load(model_path)['model_state_dict'])\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_hat = reconstruct_logits(vis_batch, model)\n",
    "probs = F.softmax(batch_hat, dim=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize_batch_logits( batch_hat.detach().cpu() , title= \"model100 predictions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize_batch( probs.detach().cpu() , title= \"model100 predictions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_seg = torch.argmax(probs,     dim=1).detach().cpu()\n",
    "true_seg = torch.argmax(vis_batch, dim=1).detach().cpu()\n",
    "\n",
    "visualize_errors(true_seg, pred_seg, 'Prediction errors visualization')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_Dice_score = evaluate_model(model, TestLoader, dice_score, device)\n",
    "print(model_Dice_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------------\n",
    "## Test Model 102"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = 'saved_models/vqvae_102_bestmodel.pth'\n",
    "\n",
    "model = VQVAE(in_channels, 32, 256)\n",
    "model.load_state_dict(torch.load(model_path)['model_state_dict'])\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_hat = reconstruct_logits(vis_batch, model)\n",
    "probs = F.softmax(batch_hat, dim=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize_batch_logits( batch_hat.detach().cpu() , title=JJJJJJJJJJJJJJJJJJJJJJJJ \"model100 predictions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize_batch( probs.detach().cpu() , title= \"model100 predictions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_seg = torch.argmax(probs,     dim=1).detach().cpu()\n",
    "true_seg = torch.argmax(vis_batch, dim=1).detach().cpu()\n",
    "\n",
    "visualize_errors(true_seg, pred_seg, 'Prediction errors visualization')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_Dice_score = evaluate_model(model, TestLoader, dice_score, device)\n",
    "print(model_Dice_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------\n",
    "# Test Model 103"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = 'saved_models/vqvae_103_bestmodel.pth'\n",
    "\n",
    "model = VQVAE(in_channels, 64, 512)\n",
    "model.load_state_dict(torch.load(model_path)['model_state_dict'])\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_hat = reconstruct_logits(vis_batch, model)\n",
    "probs = F.softmax(batch_hat, dim=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize_batch_logits( batch_hat.detach().cpu() , title=JJJJJJJJJJJJJJJJJJJJJJJJ \"model100 predictions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize_batch( probs.detach().cpu() , title= \"model100 predictions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_seg = torch.argmax(probs,     dim=1).detach().cpu()\n",
    "true_seg = torch.argmax(vis_batch, dim=1).detach().cpu()\n",
    "\n",
    "visualize_errors(true_seg, pred_seg, 'Prediction errors visualization')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_Dice_score = evaluate_model(model, TestLoader, dice_score, device)\n",
    "print(model_Dice_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------\n",
    "# Model 104"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = 'saved_models/vqvae_104_bestmodel.pth'\n",
    "\n",
    "model = VQVAE(in_channels, 64, 256)\n",
    "model.load_state_dict(torch.load(model_path)['model_state_dict'])\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_hat = reconstruct_logits(vis_batch, model)\n",
    "probs = F.softmax(batch_hat, dim=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize_batch_logits( batch_hat.detach().cpu() , title= \"model100 predictions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize_batch( probs.detach().cpu() , title= \"model100 predictions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_seg = torch.argmax(probs,     dim=1).detach().cpu()\n",
    "true_seg = torch.argmax(vis_batch, dim=1).detach().cpu()\n",
    "\n",
    "visualize_errors(true_seg, pred_seg, 'Prediction errors visualization')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_Dice_score = evaluate_model(model, TestLoader, dice_score, device)\n",
    "print(model_Dice_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------------\n",
    "----------------------\n",
    "# Re-Fit models "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### model100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = 'Re_Fit_models/vqvae_100_bestmodel.pth'\n",
    "\n",
    "model = VQVAE(in_channels, 64, 256)\n",
    "model.load_state_dict(torch.load(model_path)['model_state_dict'])\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_hat = reconstruct_logits(vis_batch, model)\n",
    "probs = F.softmax(batch_hat, dim=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize_batch_logits( batch_hat.detach().cpu() , title= \"model100 predictions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize_batch( probs.detach().cpu() , title= \"model100 predictions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_seg = torch.argmax(probs,     dim=1).detach().cpu()\n",
    "true_seg = torch.argmax(vis_batch, dim=1).detach().cpu()\n",
    "\n",
    "visualize_errors(true_seg, pred_seg, 'Prediction errors visualization')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_Dice_score = evaluate_model(model, TestLoader, dice_score, device)\n",
    "print(model_Dice_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------\n",
    "# model101"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = 'Re_Fit_models/vqvae_101_bestmodel.pth'\n",
    "\n",
    "model = VQVAE(in_channels, 64, 128)\n",
    "model.load_state_dict(torch.load(model_path)['model_state_dict'])\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_hat = reconstruct_logits(vis_batch, model)\n",
    "probs = F.softmax(batch_hat, dim=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize_batch_logits( batch_hat.detach().cpu() , title= \"model100 predictions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize_batch( probs.detach().cpu() , title= \"model100 predictions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_seg = torch.argmax(probs,     dim=1).detach().cpu()\n",
    "true_seg = torch.argmax(vis_batch, dim=1).detach().cpu()\n",
    "\n",
    "visualize_errors(true_seg, pred_seg, 'Prediction errors visualization')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_Dice_score = evaluate_model(model, TestLoader, dice_score, device)\n",
    "print(model_Dice_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------- \n",
    "# downsampling to 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = 'saved_models/vqvae_105_bestmodel.pth'\n",
    "\n",
    "model = VQVAE(in_channels, 64, 512, downsampling_factor=8)\n",
    "model.load_state_dict(torch.load(model_path)['model_state_dict'])\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_hat = reconstruct_logits(vis_batch, model)\n",
    "probs = F.softmax(batch_hat, dim=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_seg = torch.argmax(probs,     dim=1).detach().cpu()\n",
    "true_seg = torch.argmax(vis_batch, dim=1).detach().cpu()\n",
    "\n",
    "visualize_errors(true_seg, pred_seg, 'Prediction errors visualization')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_Dice_score = evaluate_model(model, TestLoader, dice_score, device)\n",
    "print(model_Dice_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python torch",
   "language": "python",
   "name": "torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
