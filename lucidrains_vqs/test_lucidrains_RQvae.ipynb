{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch \n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "from typing import List, Callable, Union, Any, TypeVar, Tuple\n",
    "Tensor = TypeVar('torch.tensor')\n",
    "\n",
    "import torch.optim as optim\n",
    "\n",
    "\n",
    "# Data preprocessing utils : \n",
    "from utils.acdc_dataset import ACDC_Dataset, One_hot_Transform, load_dataset\n",
    "from torchvision.transforms import Compose\n",
    "from torchvision import transforms\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "# Visuals utils\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "# my defined model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# from vector_quantize_pytorch import VectorQuantize\n",
    "from vector_quantize_pytorch import ResidualVQ\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "residual_vq = ResidualVQ(\n",
    "    dim = 64,\n",
    "    num_quantizers = 2,\n",
    "    codebook_size = 512,\n",
    "    # stochastic_sample_codes = True,\n",
    "    # sample_codebook_temp = 0.1,         # temperature for stochastically sampling codes, 0 would be equivalent to non-stochastic\n",
    "    # shared_codebook = True\n",
    "    commitment_weight = 1.              # whether to share the codebooks for all quantizers or not\n",
    ")\n",
    "\n",
    "residual_vq2 = ResidualVQ(\n",
    "    dim = 64,\n",
    "    num_quantizers = 2,\n",
    "    codebook_size = 512,\n",
    "    # stochastic_sample_codes = True,\n",
    "    # sample_codebook_temp = 0.1,         # temperature for stochastically sampling codes, 0 would be equivalent to non-stochastic\n",
    "    # shared_codebook = True\n",
    "    commitment_weight = 0.5              # whether to share the codebooks for all quantizers or not\n",
    ")\n",
    "\n",
    "\n",
    "x = torch.randn(16, 32, 32, 64)\n",
    "quantized, indices, commit_loss = residual_vq(x)\n",
    "quantized2, indices2, commit_loss2 = residual_vq2(x)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "residual_vq.layers[0].dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 32, 32, 2])\n"
     ]
    }
   ],
   "source": [
    "print(indices.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.9940, 0.9883]], grad_fn=<StackBackward0>)\n",
      "tensor([[0.4970, 0.4942]], grad_fn=<StackBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(commit_loss)\n",
    "print(commit_loss2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.9806, grad_fn=<SumBackward0>)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sum(commit_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = torch.randn(16,64,32,32)\n",
    "\n",
    "inputs = inputs.permute(0,3,2,1)\n",
    "quantized, indices, commit_loss = residual_vq(inputs)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 32, 32, 8])\n",
      "torch.Size([16, 32, 32, 64])\n",
      "tensor([[0.8794, 0.7752, 0.6837, 0.6034, 0.5337, 0.4719, 0.4179, 0.3711]],\n",
      "       grad_fn=<StackBackward0>)\n",
      "torch.Size([8, 512, 64])\n"
     ]
    }
   ],
   "source": [
    "print(indices.shape)\n",
    "print(quantized.shape)\n",
    "print(commit_loss)\n",
    "print(residual_vq.codebooks.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 2.0659e-01, -4.2754e-01,  5.0350e-03,  ...,  2.7439e-01,\n",
      "          2.9347e-01,  2.2752e-01],\n",
      "        [ 1.2426e-04,  2.7030e-03, -7.4224e-03,  ...,  1.2880e-02,\n",
      "          1.2001e-02, -9.1113e-03],\n",
      "        [-2.1528e-01,  1.8731e-01, -1.9458e-01,  ...,  2.6617e-01,\n",
      "          2.7675e-02, -1.1047e-02],\n",
      "        ...,\n",
      "        [ 1.3675e-01,  1.2865e-02, -5.1116e-02,  ..., -1.1161e-01,\n",
      "         -2.2483e-01,  6.3654e-01],\n",
      "        [-4.7515e-01, -3.0455e-01,  2.7131e-01,  ..., -6.7351e-01,\n",
      "          1.0754e-01, -9.6724e-02],\n",
      "        [ 3.0639e-01, -3.2468e-01,  2.5370e-01,  ...,  6.2321e-01,\n",
      "         -5.6234e-02,  1.1464e-01]])\n"
     ]
    }
   ],
   "source": [
    "print(residual_vq.codebooks[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class ResidualLayer(nn.Module):\n",
    "\n",
    "    def __init__(self,\n",
    "                 in_channels: int,\n",
    "                 out_channels: int):\n",
    "        super(ResidualLayer, self).__init__()\n",
    "        self.resblock = nn.Sequential(nn.Conv2d(in_channels, out_channels,\n",
    "                                                kernel_size=3, padding=1, bias=False),\n",
    "                                      nn.ReLU(True),\n",
    "                                      nn.Conv2d(out_channels, out_channels,\n",
    "                                                kernel_size=1, bias=False))\n",
    "\n",
    "    def forward(self, input: Tensor) -> Tensor:\n",
    "        return input + self.resblock(input)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class RQVAE(nn.Module):\n",
    "\n",
    "    def __init__(self,\n",
    "                 in_channels: int,\n",
    "                 embedding_dim: int,\n",
    "                 num_embeddings: int,\n",
    "                 num_quantizers: int,\n",
    "                 shared_codebook: bool = False,\n",
    "                #hidden_dims: List = None,\n",
    "                 downsampling_factor :int = 4,\n",
    "                 decay : float = 0.8,\n",
    "                 beta: float = 0.25,\n",
    "                #  embedding: Tensor = None,\n",
    "                 **kwargs) -> None:\n",
    "        super(RQVAE, self).__init__()\n",
    "\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.num_embeddings = num_embeddings\n",
    "        self.beta = beta\n",
    "        self.shared_codebook = shared_codebook\n",
    "        self.num_quantizers = num_quantizers\n",
    "        self.decay = decay\n",
    "\n",
    "        modules = []\n",
    "        \n",
    "        if downsampling_factor < 2 :\n",
    "            raise Warning(\"VQVAE can't have a donwsampling factor less than 2\")\n",
    "        elif downsampling_factor ==2 :\n",
    "            hidden_dims = [64]\n",
    "        elif downsampling_factor == 4 :\n",
    "            hidden_dims = [64, 128]\n",
    "        elif downsampling_factor == 8 :\n",
    "            hidden_dims = [64, 128, 256]\n",
    "        else:\n",
    "            assert(\"donwsamlping factor must be one of the following values : {2,4,8}\")\n",
    "\n",
    "\n",
    "\n",
    "        # Build Encoder\n",
    "        for h_dim in hidden_dims:\n",
    "            modules.append(\n",
    "                nn.Sequential(\n",
    "                    nn.Conv2d(in_channels, out_channels=h_dim,\n",
    "                              kernel_size=4, stride=2, padding=1),\n",
    "                    nn.LeakyReLU())\n",
    "            )\n",
    "            in_channels = h_dim\n",
    "\n",
    "        modules.append(\n",
    "            nn.Sequential(\n",
    "                nn.Conv2d(in_channels, in_channels,\n",
    "                          kernel_size=3, stride=1, padding=1),\n",
    "                nn.LeakyReLU())\n",
    "        )\n",
    "\n",
    "        for _ in range(2):\n",
    "            modules.append(ResidualLayer(in_channels, in_channels))\n",
    "        modules.append(nn.LeakyReLU())\n",
    "\n",
    "        modules.append(\n",
    "            nn.Sequential(\n",
    "                nn.Conv2d(in_channels, embedding_dim,\n",
    "                          kernel_size=1, stride=1),\n",
    "                nn.LeakyReLU())\n",
    "        )\n",
    "\n",
    "        self.encoder = nn.Sequential(*modules)\n",
    "\n",
    "        self.vq_layer = ResidualVQ(dim = embedding_dim,\n",
    "                                    codebook_size = num_embeddings,\n",
    "                                    commitment_weight = self.beta,\n",
    "                                    decay = self.decay,\n",
    "                                    num_quantizers = self.num_quantizers,\n",
    "                                    shared_codebook = self.shared_codebook,\n",
    "                                    )\n",
    "\n",
    "        # Build Decoder\n",
    "        modules = []\n",
    "        modules.append(\n",
    "            nn.Sequential(\n",
    "                nn.Conv2d(embedding_dim,\n",
    "                          hidden_dims[-1],\n",
    "                          kernel_size=3,\n",
    "                          stride=1,\n",
    "                          padding=1),\n",
    "                nn.LeakyReLU())\n",
    "        )\n",
    "\n",
    "        for _ in range(2):\n",
    "            modules.append(ResidualLayer(hidden_dims[-1], hidden_dims[-1]))\n",
    "\n",
    "        modules.append(nn.LeakyReLU())\n",
    "\n",
    "        hidden_dims.reverse()\n",
    "\n",
    "        for i in range(len(hidden_dims) - 1):\n",
    "            modules.append(\n",
    "                nn.Sequential(\n",
    "                    nn.ConvTranspose2d(hidden_dims[i],\n",
    "                                       hidden_dims[i + 1],\n",
    "                                       kernel_size=4,\n",
    "                                       stride=2,\n",
    "                                       padding=1),\n",
    "                    nn.LeakyReLU())\n",
    "            )\n",
    "\n",
    "        modules.append(\n",
    "            nn.Sequential(\n",
    "                nn.ConvTranspose2d(hidden_dims[-1],\n",
    "                                   out_channels=4,\n",
    "                                   kernel_size=4,\n",
    "                                   stride=2, padding=1),\n",
    "                nn.ReLU()\n",
    "                ))\n",
    "\n",
    "        self.decoder = nn.Sequential(*modules)\n",
    "\n",
    "    def encode(self, input: Tensor) -> List[Tensor]:\n",
    "        \"\"\"\n",
    "        Encodes the input by passing through the encoder network\n",
    "        and returns the latent codes.\n",
    "        :param input: (Tensor) Input tensor to encoder [N x C x H x W]\n",
    "        :return: (Tensor) List of latent codes\n",
    "        \"\"\"\n",
    "        result = self.encoder(input)\n",
    "        return [result]\n",
    "\n",
    "    def decode(self, z: Tensor) -> Tensor:\n",
    "        \"\"\"\n",
    "        Maps the given latent codes\n",
    "        onto the image space.\n",
    "        :param z: (Tensor) [B x D x H x W]\n",
    "        :return: (Tensor) [B x C x H x W]\n",
    "        \"\"\"\n",
    "\n",
    "        result = self.decoder(z)\n",
    "        return result\n",
    "\n",
    "    def forward(self, inputs: Tensor, **kwargs) -> List[Tensor]:\n",
    "        encoding = self.encode(inputs)[0]\n",
    "        encoding = encoding.permute(0, 2, 3, 1)\n",
    "        quantized_inputs, indices, commitment_loss_beta = self.vq_layer(encoding)\n",
    "        quantized_inputs = quantized_inputs.permute(0, 3, 1, 2)\n",
    "        return [self.decode(quantized_inputs), inputs, indices, commitment_loss_beta]\n",
    "\n",
    "    ## !! update codebook_usage\n",
    "\n",
    "    # def codebook_usage(self, inputs: Tensor, **kwargs) -> List[Tensor]:\n",
    "    #     encoding = self.encode(inputs)[0]\n",
    "    #     quantized_hist = self.vq_layer.quantized_latents_hist(encoding)\n",
    "    #     return quantized_hist\n",
    "\n",
    "\n",
    "\n",
    "    def loss_function(self,\n",
    "                      *args,\n",
    "                      **kwargs) -> dict:\n",
    "        \"\"\"\n",
    "        :param args:\n",
    "        :param kwargs:\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        recons = args[0]\n",
    "        inputs = args[1]\n",
    "        indices = args[2]\n",
    "        commitment_loss_beta = args[3]\n",
    "\n",
    "        recons_loss = F.cross_entropy(recons,inputs)\n",
    "\n",
    "        loss = recons_loss + torch.sum(commitment_loss_beta) # sum over all commitement losses of all codebooks\n",
    "        return {'loss': loss,\n",
    "                'Reconstruction_Loss': recons_loss,\n",
    "                'commitement Loss':commitment_loss_beta}\n",
    "\n",
    "    # def sample(self,\n",
    "    #            num_samples: int,\n",
    "    #            current_device: Union[int, str], **kwargs) -> Tensor:\n",
    "    #     raise Warning('VQVAE sampler is not implemented.')\n",
    "\n",
    "    def generate(self, x: Tensor, **kwargs) -> Tensor:\n",
    "        \"\"\"\n",
    "        Given an input image x, returns the reconstructed image\n",
    "        :param x: (Tensor) [B x C x H x W]\n",
    "        :return: (Tensor) [B x C x H x W]\n",
    "        \"\"\"\n",
    "\n",
    "\n",
    "    def codebook_usage(self, inputs):\n",
    "        encoding = self.encode(inputs)[0]\n",
    "        encoding = encoding.permute(0, 2, 3, 1)\n",
    "        _, indices, _ = self.vq_layer(encoding)\n",
    "\n",
    "        num_codebooks = indices.shape[-1]\n",
    "        embedding_histogram = torch.zeros(num_codebooks,self.vq_layer.codebook_size )\n",
    "\n",
    "        for i in range(num_codebooks):\n",
    "            encoding_inds_flat_i = indices[... , i].view(-1)   # [B,H,W] --> [B,H,W]\n",
    "            embedding_histogram_i = torch.bincount(encoding_inds_flat_i, minlength=self.vq_layer.codebook_size)  # Count occurrences of each embedding\n",
    "            embedding_histogram[i] = embedding_histogram_i\n",
    "            \n",
    "        return embedding_histogram\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 32, 32])"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indices[... , 0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "K =  512 # num_embeddings\n",
    "D =  64 # embedding_dim\n",
    "in_channels = 4 \n",
    "num_quantizers = 2\n",
    "downsampling_factor = 4\n",
    "shared_codebook = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ACDC_VQVAE = VQVAE(in_channels, D, K, downsampling_factor)\n",
    "model = RQVAE(in_channels= in_channels,\n",
    "                embedding_dim= D,\n",
    "                num_embeddings= K,\n",
    "                num_quantizers= num_quantizers,\n",
    "                shared_codebook= shared_codebook,\n",
    "                downsampling_factor= downsampling_factor )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_tensor = torch.randn(16, 4, 128, 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_tensor, inputs, indices, commit_losss = model(input_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 4, 128, 128])\n",
      "torch.Size([16, 32, 32, 2])\n",
      "tensor(0.0010, grad_fn=<SumBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(output_tensor.shape)\n",
    "# print(input_tensor - inputs)\n",
    "print(indices.shape)\n",
    "print(torch.sum(commit_losss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 512])\n"
     ]
    }
   ],
   "source": [
    "hist_codebooks = model.codebook_usage(input_tesor)\n",
    "print(hist_codebooks.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "ename": "SolveValueException",
     "evalue": "Failed to solve values of expressions. Found contradictory values {16, 1} for equivalent expressions {'1', 'h', '16'}\nInput:\n    'h [c] d = 1 512 64'\n    'h b n = 16 32 32'\n    'h b n d = None'\n    '1 = 1'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mSolveValueException\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[87], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m model\u001b[38;5;241m.\u001b[39meval()\n\u001b[1;32m      2\u001b[0m input_tensor \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrandn(\u001b[38;5;241m16\u001b[39m, \u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m128\u001b[39m, \u001b[38;5;241m128\u001b[39m)\n\u001b[0;32m----> 3\u001b[0m output_tensor, inputs, indices, commit_losss \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_tensor\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/torch/lib/python3.9/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/torch/lib/python3.9/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "Cell \u001b[0;32mIn[14], line 160\u001b[0m, in \u001b[0;36mVQVAE.forward\u001b[0;34m(self, inputs, **kwargs)\u001b[0m\n\u001b[1;32m    158\u001b[0m encoding \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencode(inputs)[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    159\u001b[0m encoding \u001b[38;5;241m=\u001b[39m encoding\u001b[38;5;241m.\u001b[39mpermute(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m--> 160\u001b[0m quantized_inputs, indices, commitment_loss_beta \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvq_layer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    161\u001b[0m quantized_inputs \u001b[38;5;241m=\u001b[39m quantized_inputs\u001b[38;5;241m.\u001b[39mpermute(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m    162\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdecode(quantized_inputs), inputs, indices, commitment_loss_beta]\n",
      "File \u001b[0;32m~/anaconda3/envs/torch/lib/python3.9/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/torch/lib/python3.9/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/anaconda3/envs/torch/lib/python3.9/site-packages/vector_quantize_pytorch/residual_vq.py:375\u001b[0m, in \u001b[0;36mResidualVQ.forward\u001b[0;34m(self, x, mask, indices, return_all_codes, sample_codebook_temp, freeze_codebook, rand_quantize_dropout_fixed_seed)\u001b[0m\n\u001b[1;32m    371\u001b[0m all_residuals\u001b[38;5;241m.\u001b[39mappend(residual)\n\u001b[1;32m    373\u001b[0m \u001b[38;5;66;03m# vector quantize forward\u001b[39;00m\n\u001b[0;32m--> 375\u001b[0m quantized, \u001b[38;5;241m*\u001b[39mrest \u001b[38;5;241m=\u001b[39m \u001b[43mvq\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    376\u001b[0m \u001b[43m    \u001b[49m\u001b[43mresidual\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    377\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmask\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    378\u001b[0m \u001b[43m    \u001b[49m\u001b[43mindices\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mlayer_indices\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    379\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_codebook_temp\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43msample_codebook_temp\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    380\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfreeze_codebook\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mfreeze_codebook\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    381\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcodebook_transform_fn\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmaybe_mlp\u001b[49m\n\u001b[1;32m    382\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    384\u001b[0m residual \u001b[38;5;241m=\u001b[39m residual \u001b[38;5;241m-\u001b[39m quantized\u001b[38;5;241m.\u001b[39mdetach()\n\u001b[1;32m    385\u001b[0m quantized_out \u001b[38;5;241m=\u001b[39m quantized_out \u001b[38;5;241m+\u001b[39m quantized\n",
      "File \u001b[0;32m~/anaconda3/envs/torch/lib/python3.9/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/torch/lib/python3.9/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/anaconda3/envs/torch/lib/python3.9/site-packages/vector_quantize_pytorch/vector_quantize_pytorch.py:1087\u001b[0m, in \u001b[0;36mVectorQuantize.forward\u001b[0;34m(self, x, indices, mask, lens, sample_codebook_temp, freeze_codebook, return_loss_breakdown, codebook_transform_fn)\u001b[0m\n\u001b[1;32m   1078\u001b[0m codebook_forward_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(\n\u001b[1;32m   1079\u001b[0m     sample_codebook_temp \u001b[38;5;241m=\u001b[39m sample_codebook_temp,\n\u001b[1;32m   1080\u001b[0m     mask \u001b[38;5;241m=\u001b[39m mask,\n\u001b[1;32m   1081\u001b[0m     freeze_codebook \u001b[38;5;241m=\u001b[39m freeze_codebook,\n\u001b[1;32m   1082\u001b[0m     codebook_transform_fn \u001b[38;5;241m=\u001b[39m codebook_transform_fn\n\u001b[1;32m   1083\u001b[0m )\n\u001b[1;32m   1085\u001b[0m \u001b[38;5;66;03m# quantize\u001b[39;00m\n\u001b[0;32m-> 1087\u001b[0m quantize, embed_ind, distances \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_codebook\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcodebook_forward_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1089\u001b[0m \u001b[38;5;66;03m# losses for loss breakdown\u001b[39;00m\n\u001b[1;32m   1091\u001b[0m commit_loss \u001b[38;5;241m=\u001b[39m orthogonal_reg_loss \u001b[38;5;241m=\u001b[39m inplace_optimize_loss \u001b[38;5;241m=\u001b[39m codebook_diversity_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mzero\n",
      "File \u001b[0;32m~/anaconda3/envs/torch/lib/python3.9/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/torch/lib/python3.9/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/anaconda3/envs/torch/lib/python3.9/site-packages/torch/amp/autocast_mode.py:44\u001b[0m, in \u001b[0;36mautocast_decorator.<locals>.decorate_autocast\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m     42\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_autocast\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     43\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m autocast_instance:\n\u001b[0;32m---> 44\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/torch/lib/python3.9/site-packages/vector_quantize_pytorch/vector_quantize_pytorch.py:565\u001b[0m, in \u001b[0;36mEuclideanCodebook.forward\u001b[0;34m(self, x, sample_codebook_temp, mask, freeze_codebook, codebook_transform_fn)\u001b[0m\n\u001b[1;32m    563\u001b[0m         quantize \u001b[38;5;241m=\u001b[39m einx\u001b[38;5;241m.\u001b[39mget_at(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mh b n [c] d, h b n -> h b n d\u001b[39m\u001b[38;5;124m'\u001b[39m, transformed_embed, embed_ind)\n\u001b[1;32m    564\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 565\u001b[0m         quantize \u001b[38;5;241m=\u001b[39m \u001b[43meinx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_at\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mh [c] d, h b n -> h b n d\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membed\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membed_ind\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    567\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mema_update \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m freeze_codebook:\n\u001b[1;32m    569\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maffine_param:\n",
      "File \u001b[0;32m~/anaconda3/envs/torch/lib/python3.9/site-packages/einx/traceback_util.py:71\u001b[0m, in \u001b[0;36mfilter.<locals>.func_with_reraise\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     70\u001b[0m     tb \u001b[38;5;241m=\u001b[39m _filter_tb(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m---> 71\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     72\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     73\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m tb\n",
      "\u001b[0;31mSolveValueException\u001b[0m: Failed to solve values of expressions. Found contradictory values {16, 1} for equivalent expressions {'1', 'h', '16'}\nInput:\n    'h [c] d = 1 512 64'\n    'h b n = 16 32 32'\n    'h b n d = None'\n    '1 = 1'\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "input_tensor = torch.randn(16, 4, 128, 128)\n",
    "output_tensor, inputs, indices, commit_losss = model(input_tensor)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python torch",
   "language": "python",
   "name": "torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
