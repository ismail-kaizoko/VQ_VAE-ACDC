{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch \n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "import torch.optim as optim\n",
    "\n",
    "\n",
    "# Data preprocessing utils : \n",
    "from torchvision.transforms import Compose\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Visuals utils\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "# my defined model\n",
    "from utils.acdc_dataset import *\n",
    "from utils.funcs import *\n",
    "from utils.vqvae import *\n",
    "from utils.launcher_utils import *\n",
    "\n",
    "import json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def load_model_from_metadata(json_filepath):\n",
    "    \"\"\"\n",
    "    Load model parameters from a JSON file and instantiate a new model.\n",
    "\n",
    "    Args:\n",
    "        json_filepath (str): Path to the JSON file containing the metadata.\n",
    "\n",
    "    Returns:\n",
    "        model: A new instance of the model with the saved parameters.\n",
    "    \"\"\"\n",
    "    # Load the JSON file\n",
    "    with open(json_filepath, 'r') as f:\n",
    "        metadata = json.load(f)\n",
    "\n",
    "    # Extract model parameters from the metadata\n",
    "    model_params = metadata.get(\"model_parameters\", {})\n",
    "    print(\"Loaded model parameters:\", model_params)\n",
    "\n",
    "    # Instantiate a new model with the extracted parameters\n",
    "    model = VQVAE(**model_params)\n",
    "\n",
    "    return model\n",
    "\n",
    "def shrink_model_from_metadata(json_filepath, new_K):\n",
    "    \"\"\"\n",
    "    Load model parameters from a JSON file and instantiate a new model.\n",
    "\n",
    "    Args:\n",
    "        json_filepath (str): Path to the JSON file containing the metadata.\n",
    "\n",
    "    Returns:\n",
    "        model: A new instance of the model with the saved parameters.\n",
    "    \"\"\"\n",
    "    # Load the JSON file\n",
    "    with open(json_filepath, 'r') as f:\n",
    "        metadata = json.load(f)\n",
    "\n",
    "    # Extract model parameters from the metadata\n",
    "    model_params = metadata.get(\"model_parameters\", {})\n",
    "\n",
    "    #reduce the size of K : \n",
    "    model_params['num_embeddings'] = new_K\n",
    "    print(\"Loaded model parameters:\", model_params)\n",
    "\n",
    "    # Instantiate a new model with the extracted parameters\n",
    "    model = VQVAE(**model_params)\n",
    "\n",
    "    return model\n",
    "\n",
    "# Example usage:\n",
    "# Assuming VQVAE is your model class\n",
    "# json_filepath = \"./training_metadata/training_metadata_20231025_123456.json\"\n",
    "# model2 = load_model_from_metadata(json_filepath, VQVAE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'embedding_dim': 64, 'num_embeddings': 512, 'downsampling_factor': 8, 'residual': False, 'num_quantizers': 2, 'shared_codebook': False, 'beta': 0.25, 'decay': 0.8}\n",
      "{'embedding_dim': 64, 'num_embeddings': 128, 'downsampling_factor': 8, 'residual': False, 'num_quantizers': 2, 'shared_codebook': False, 'beta': 0.25, 'decay': 0.8}\n"
     ]
    }
   ],
   "source": [
    "json_filepath = 'saved_models/seg/random.pth'.replace('.pth', '.json')\n",
    "with open(json_filepath, 'r') as f:\n",
    "    metadata = json.load(f)\n",
    "\n",
    "model_params = metadata.get(\"model_parameters\", {})\n",
    "training_params =  metadata.get(\"training_parameters\", {})\n",
    "\n",
    "\n",
    "print(model_params)\n",
    "new_K = 128\n",
    "#reduce the size of K : \n",
    "model_params['num_embeddings'] = new_K\n",
    "\n",
    "print(model_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model parameters: {'embedding_dim': 64, 'num_embeddings': 512, 'downsampling_factor': 8, 'residual': False, 'num_quantizers': 2, 'shared_codebook': False, 'beta': 0.25, 'decay': 0.8}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "baseline_model_path = 'saved_models/seg/random.pth'\n",
    "baseline_model_metdat = (baseline_model_path).replace('.pth', '.json')\n",
    "baseline_model = load_model_from_metadata(baseline_model_metdat).to(device)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4188434/2651044302.py:4: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(baseline_model_path)\n"
     ]
    }
   ],
   "source": [
    "# saving the previous model encoder and decoder : \n",
    "\n",
    "# Load the saved model checkpoint\n",
    "checkpoint = torch.load(baseline_model_path)\n",
    "# Filter the encoder parameters\n",
    "encoder_state_dict = {k: v for k, v in checkpoint['model_state_dict'].items() if k.startswith('encoder.')}\n",
    "# Filter the decoder parameters\n",
    "decoder_state_dict = {k: v for k, v in checkpoint['model_state_dict'].items() if k.startswith('decoder.')}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model parameters: {'embedding_dim': 64, 'num_embeddings': 128, 'downsampling_factor': 8, 'residual': False, 'num_quantizers': 2, 'shared_codebook': False, 'beta': 0.25, 'decay': 0.8, 'data_mod': 'SEG'}\n"
     ]
    }
   ],
   "source": [
    "model = shrink_model_from_metadata(baseline_model_metdat, 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VQVAE(\n",
       "  (encoder): Sequential(\n",
       "    (0): Sequential(\n",
       "      (0): Conv2d(4, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "    )\n",
       "    (1): Sequential(\n",
       "      (0): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "    )\n",
       "    (2): Sequential(\n",
       "      (0): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "    )\n",
       "    (3): Sequential(\n",
       "      (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "    )\n",
       "    (4): ResidualLayer(\n",
       "      (resblock): Sequential(\n",
       "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (5): ResidualLayer(\n",
       "      (resblock): Sequential(\n",
       "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (6): LeakyReLU(negative_slope=0.01)\n",
       "    (7): Sequential(\n",
       "      (0): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "    )\n",
       "  )\n",
       "  (vq_layer): VectorQuantize(\n",
       "    (project_in): Identity()\n",
       "    (project_out): Identity()\n",
       "    (_codebook): EuclideanCodebook()\n",
       "  )\n",
       "  (decoder): Sequential(\n",
       "    (0): Sequential(\n",
       "      (0): Conv2d(64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "    )\n",
       "    (1): ResidualLayer(\n",
       "      (resblock): Sequential(\n",
       "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (2): ResidualLayer(\n",
       "      (resblock): Sequential(\n",
       "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (3): LeakyReLU(negative_slope=0.01)\n",
       "    (4): Sequential(\n",
       "      (0): ConvTranspose2d(256, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "    )\n",
       "    (5): Sequential(\n",
       "      (0): ConvTranspose2d(128, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "    )\n",
       "    (6): Sequential(\n",
       "      (0): ConvTranspose2d(64, 4, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "      (1): ReLU()\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'SEG'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_params['data_mod']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_mod = training_params['data_mod']\n",
    "L = training_params['L']\n",
    "batch_size = training_params['batch_size']\n",
    "\n",
    "#################### dataset init ######################\n",
    "dataset_path = \"/home/ids/ihamdaoui-21/ACDC/database\"\n",
    "\n",
    "train_set_path = os.path.join(dataset_path, \"training\")\n",
    "test_set_path  = os.path.join(dataset_path, \"testing\")\n",
    "\n",
    "\n",
    "train_dataset = load_dataset(train_set_path, modality= data_mod)\n",
    "test_dataset  = load_dataset(test_set_path, modality= data_mod)\n",
    "\n",
    "\n",
    "if data_mod == 'SEG':\n",
    "    input_transforms = Compose([\n",
    "        transforms.Resize(size=(L,L), interpolation=transforms.InterpolationMode.NEAREST),\n",
    "        One_hot_Transform(num_classes=4)\n",
    "        ])\n",
    "else : \n",
    "    input_transforms = Compose([\n",
    "        transforms.Resize(size=(L,L), interpolation=transforms.InterpolationMode.NEAREST),\n",
    "        PercentileClip(lower_percentile=1, upper_percentile=99),\n",
    "        MinMaxNormalize(min_value=0.0, max_value=1.0),\n",
    "        ])\n",
    "\n",
    "\n",
    "TrainDataset = ACDC_Dataset(data = train_dataset, transforms= input_transforms) \n",
    "TestDataset  = ACDC_Dataset(data = test_dataset, transforms= input_transforms)\n",
    "\n",
    "TrainLoader  = DataLoader(TrainDataset, batch_size = batch_size, shuffle = True)\n",
    "TestLoader   = DataLoader(TestDataset , batch_size = batch_size, shuffle = False)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-7.2677e-04, -7.1296e-04, -7.2102e-04,  ..., -6.5267e-04,\n",
      "         -6.6954e-04, -6.2945e-04],\n",
      "        [ 4.4607e-02,  4.4302e-02,  4.3896e-02,  ...,  4.7708e-02,\n",
      "          4.6804e-02,  4.1788e-02],\n",
      "        [ 2.6217e-02,  2.6229e-02,  2.6229e-02,  ...,  1.9907e-02,\n",
      "          1.9907e-02,  2.4059e-02],\n",
      "        ...,\n",
      "        [-7.4128e-06, -2.0875e-05, -2.1214e-05,  ..., -1.9673e-05,\n",
      "         -2.0442e-05, -2.4311e-05],\n",
      "        [ 2.5740e-02,  2.7776e-02,  2.7776e-02,  ...,  1.9694e-02,\n",
      "          1.9658e-02,  1.9676e-02],\n",
      "        [ 1.2430e-02,  1.2300e-02,  1.2415e-02,  ...,  6.7612e-03,\n",
      "          9.4946e-03,  1.0337e-02]])\n"
     ]
    }
   ],
   "source": [
    "# we are going to pass through the whole dataset, which results on \n",
    "\n",
    "latent_vectors = []\n",
    "\n",
    "# Process the dataset\n",
    "with torch.no_grad():  # No need to track gradients\n",
    "    for batch in TrainLoader:\n",
    "        # Pass the batch through the encoder\n",
    "        encoded = baseline_model.encode(batch.float().to(device))[0]  # Output shape: (batch_size, 32, 32, 32)\n",
    "        \n",
    "        # Flatten the encoded output to (batch_size, 32*32)\n",
    "        encoded_flat = encoded.view(encoded.size(0), 64, -1).permute(0, 2, 1)  # Shape: (batch_size, 1024, 64)\n",
    "        \n",
    "        # Now flatten across the batch and spatial dimensions to (batch_size * 1024, 64)\n",
    "        encoded_flat = encoded_flat.reshape(-1, 64)\n",
    "        \n",
    "        # Convert the tensor to NumPy and store it\n",
    "        latent_vectors.append(encoded_flat.cpu().numpy())\n",
    "\n",
    "# Concatenate all the latent vectors into a single NumPy array\n",
    "latent_vectors = np.concatenate(latent_vectors, axis=0)  # Shape: (size_of_dataset, 32*32)\n",
    "\n",
    "# # Optionally, save the latent vectors to disk\n",
    "# np.save('latent_vectors.npy', latent_vectors)\n",
    "from sklearn.cluster import kmeans_plusplus\n",
    "\n",
    "# Calculate seeds from k-means++\n",
    "centers_init, indices = kmeans_plusplus(latent_vectors, n_clusters= new_K)\n",
    "\n",
    "new_codebook = torch.from_numpy(centers_init)\n",
    "print(new_codebook)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.7541, 0.6493, 0.3391,  ..., 0.6177, 0.7495, 0.7156],\n",
      "        [0.3443, 0.3010, 0.3454,  ..., 0.1826, 0.8266, 0.8625],\n",
      "        [0.7483, 0.8908, 0.5861,  ..., 0.6253, 0.8567, 0.5477],\n",
      "        ...,\n",
      "        [0.6016, 0.5963, 0.1018,  ..., 0.1677, 0.6526, 0.5958],\n",
      "        [0.9381, 0.6252, 0.0850,  ..., 0.2351, 0.3698, 0.1681],\n",
      "        [0.5812, 0.5719, 0.8438,  ..., 0.9017, 0.9298, 0.0963]],\n",
      "       device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(model.vq_layer.codebook)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-7.2677e-04, -7.1296e-04, -7.2102e-04,  ..., -6.5267e-04,\n",
      "         -6.6954e-04, -6.2945e-04],\n",
      "        [ 4.4607e-02,  4.4302e-02,  4.3896e-02,  ...,  4.7708e-02,\n",
      "          4.6804e-02,  4.1788e-02],\n",
      "        [ 2.6217e-02,  2.6229e-02,  2.6229e-02,  ...,  1.9907e-02,\n",
      "          1.9907e-02,  2.4059e-02],\n",
      "        ...,\n",
      "        [-7.4128e-06, -2.0875e-05, -2.1214e-05,  ..., -1.9673e-05,\n",
      "         -2.0442e-05, -2.4311e-05],\n",
      "        [ 2.5740e-02,  2.7776e-02,  2.7776e-02,  ...,  1.9694e-02,\n",
      "          1.9658e-02,  1.9676e-02],\n",
      "        [ 1.2430e-02,  1.2300e-02,  1.2415e-02,  ...,  6.7612e-03,\n",
      "          9.4946e-03,  1.0337e-02]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "model.vq_layer.codebook = new_codebook\n",
    "print(model.vq_layer.codebook)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[[[ 0.0244, -0.0428,  0.0740,  0.0781],\n",
      "          [ 0.1232,  0.0612,  0.0532,  0.0446],\n",
      "          [ 0.0044, -0.1115,  0.0124,  0.1156],\n",
      "          [-0.0906,  0.0188,  0.1185,  0.0551]],\n",
      "\n",
      "         [[-0.0590, -0.0583,  0.0029, -0.0477],\n",
      "          [ 0.0908, -0.1074,  0.0509, -0.1155],\n",
      "          [-0.0379, -0.0708, -0.0016, -0.0948],\n",
      "          [ 0.0435, -0.1248, -0.0533, -0.1147]],\n",
      "\n",
      "         [[-0.0910,  0.0394, -0.1198, -0.0950],\n",
      "          [-0.0304, -0.0315,  0.0967, -0.0297],\n",
      "          [ 0.0692, -0.1252, -0.0929, -0.0483],\n",
      "          [ 0.0631,  0.1045, -0.0244, -0.0493]],\n",
      "\n",
      "         [[ 0.0494,  0.0723, -0.0519,  0.0014],\n",
      "          [-0.0068, -0.0452,  0.0789,  0.0938],\n",
      "          [-0.1046, -0.0022,  0.0069, -0.0415],\n",
      "          [-0.1134, -0.0927,  0.0048,  0.0249]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0533,  0.0018, -0.1011, -0.0924],\n",
      "          [ 0.0523, -0.0805, -0.0791,  0.0508],\n",
      "          [-0.0997, -0.1199,  0.1092, -0.0663],\n",
      "          [-0.0874, -0.0016, -0.0824, -0.0822]],\n",
      "\n",
      "         [[ 0.0368, -0.0033,  0.0615, -0.0006],\n",
      "          [-0.0038,  0.1248,  0.0514, -0.0860],\n",
      "          [-0.0858, -0.1217,  0.0893, -0.0678],\n",
      "          [-0.1166,  0.1021,  0.1070,  0.0314]],\n",
      "\n",
      "         [[-0.0191, -0.0289, -0.1088,  0.0123],\n",
      "          [-0.1191,  0.0675, -0.0309,  0.0553],\n",
      "          [ 0.0552, -0.0660,  0.0983,  0.0302],\n",
      "          [ 0.1083,  0.0174,  0.0611,  0.0990]],\n",
      "\n",
      "         [[-0.0638,  0.0058,  0.0253,  0.0377],\n",
      "          [ 0.0277, -0.0345,  0.0909, -0.0273],\n",
      "          [-0.1161, -0.0198, -0.0306,  0.0462],\n",
      "          [ 0.0074,  0.0834, -0.0947,  0.0021]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0548, -0.0588,  0.0197, -0.0524],\n",
      "          [ 0.0100,  0.0200, -0.0175, -0.0470],\n",
      "          [ 0.1138, -0.0317, -0.0708,  0.0883],\n",
      "          [-0.0546, -0.0386,  0.1202,  0.0470]],\n",
      "\n",
      "         [[-0.0047, -0.0798,  0.0554,  0.0187],\n",
      "          [ 0.1133, -0.0025, -0.0274, -0.0356],\n",
      "          [-0.0245, -0.1023, -0.0508,  0.1174],\n",
      "          [-0.0051,  0.0693, -0.0621,  0.1189]],\n",
      "\n",
      "         [[ 0.0906,  0.0984, -0.0535, -0.0085],\n",
      "          [ 0.0877, -0.0049, -0.0355,  0.1185],\n",
      "          [ 0.0564,  0.0589, -0.0661,  0.0478],\n",
      "          [ 0.1123,  0.0792,  0.1169,  0.0361]],\n",
      "\n",
      "         [[-0.0746, -0.0577,  0.0044,  0.0275],\n",
      "          [ 0.1056, -0.0765,  0.1198, -0.0065],\n",
      "          [ 0.0335, -0.0223, -0.1044,  0.0934],\n",
      "          [-0.0207,  0.1131,  0.0233,  0.0778]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 0.0036, -0.0715, -0.0179,  0.0079],\n",
      "          [-0.0992,  0.0160,  0.0129,  0.1036],\n",
      "          [-0.1153,  0.0189,  0.0292,  0.1138],\n",
      "          [-0.0414,  0.0947,  0.0218, -0.0739]],\n",
      "\n",
      "         [[ 0.1149,  0.0853,  0.0005, -0.0407],\n",
      "          [ 0.0664, -0.0066,  0.1175, -0.0791],\n",
      "          [ 0.0790,  0.0525, -0.0491,  0.0068],\n",
      "          [ 0.0462, -0.0209, -0.0417, -0.1028]],\n",
      "\n",
      "         [[-0.1298,  0.1044, -0.0952, -0.1209],\n",
      "          [-0.0551,  0.0487, -0.0351,  0.0769],\n",
      "          [-0.1128, -0.0947, -0.0981,  0.0827],\n",
      "          [ 0.1154,  0.0325, -0.0055,  0.0580]],\n",
      "\n",
      "         [[ 0.0657,  0.0697,  0.0943,  0.0188],\n",
      "          [-0.0679, -0.0862, -0.0791,  0.0965],\n",
      "          [-0.0132, -0.0407, -0.0272, -0.1064],\n",
      "          [-0.1212,  0.1010,  0.0050,  0.0801]]],\n",
      "\n",
      "\n",
      "        [[[-0.1131, -0.0539, -0.0402, -0.0970],\n",
      "          [-0.0571,  0.0428, -0.0179, -0.0066],\n",
      "          [ 0.1175,  0.0064,  0.0750,  0.0975],\n",
      "          [-0.1130,  0.0761,  0.0179, -0.1033]],\n",
      "\n",
      "         [[-0.0296,  0.0776, -0.1052,  0.0310],\n",
      "          [-0.1100, -0.1022,  0.0423,  0.0068],\n",
      "          [-0.0823, -0.0933, -0.1045,  0.0708],\n",
      "          [-0.0477, -0.0253,  0.0424,  0.1072]],\n",
      "\n",
      "         [[ 0.1074,  0.0711,  0.0011,  0.0687],\n",
      "          [-0.0125,  0.0578, -0.0898,  0.1020],\n",
      "          [-0.0875, -0.0676, -0.0017,  0.0602],\n",
      "          [ 0.1107, -0.0795,  0.0069, -0.0156]],\n",
      "\n",
      "         [[ 0.0270,  0.0482, -0.0540, -0.1107],\n",
      "          [-0.0033, -0.0627, -0.0585,  0.0037],\n",
      "          [-0.0152,  0.1165, -0.0562,  0.1349],\n",
      "          [ 0.1093, -0.0649,  0.0223, -0.0364]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0650, -0.0526, -0.0952, -0.0798],\n",
      "          [ 0.0019,  0.1114,  0.1185,  0.0197],\n",
      "          [ 0.0036,  0.0276,  0.0534,  0.0913],\n",
      "          [ 0.0534,  0.0383, -0.0186,  0.0660]],\n",
      "\n",
      "         [[-0.0605, -0.0573, -0.1328,  0.0757],\n",
      "          [-0.0374, -0.0212,  0.0551, -0.0709],\n",
      "          [-0.0189, -0.0608,  0.0310,  0.0671],\n",
      "          [ 0.0227, -0.0256, -0.1310, -0.0178]],\n",
      "\n",
      "         [[-0.1139, -0.1050, -0.1278, -0.0945],\n",
      "          [ 0.0661, -0.0838,  0.0292, -0.0051],\n",
      "          [-0.1111,  0.1030, -0.0794, -0.0477],\n",
      "          [-0.1160,  0.0522, -0.0909, -0.1057]],\n",
      "\n",
      "         [[ 0.0466, -0.0326, -0.1162, -0.1185],\n",
      "          [ 0.0413, -0.0683,  0.0232, -0.0227],\n",
      "          [-0.0851,  0.1067, -0.0796, -0.0623],\n",
      "          [-0.0340,  0.0267,  0.0290, -0.0387]]]], device='cuda:0',\n",
      "       requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "print(model.encoder[0][0].weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the encoder and decoder weights into the new model\n",
    "# Remove the 'encoder.' prefix from all keys in encoder_state_dict\n",
    "encoder_state_dict = {k.replace('encoder.', ''): v for k, v in encoder_state_dict.items()}\n",
    "model.encoder.load_state_dict(encoder_state_dict)\n",
    "\n",
    "# Remove the 'encoder.' prefix from all keys in encoder_state_dict\n",
    "decoder_state_dict = {k.replace('decoder.', ''): v for k, v in decoder_state_dict.items()}\n",
    "model.decoder.load_state_dict(decoder_state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[[[ 0.0244, -0.0428,  0.0740,  0.0781],\n",
      "          [ 0.1232,  0.0612,  0.0532,  0.0446],\n",
      "          [ 0.0044, -0.1115,  0.0124,  0.1156],\n",
      "          [-0.0906,  0.0188,  0.1185,  0.0551]],\n",
      "\n",
      "         [[-0.0590, -0.0583,  0.0029, -0.0477],\n",
      "          [ 0.0908, -0.1074,  0.0509, -0.1155],\n",
      "          [-0.0379, -0.0708, -0.0016, -0.0948],\n",
      "          [ 0.0435, -0.1248, -0.0533, -0.1147]],\n",
      "\n",
      "         [[-0.0910,  0.0394, -0.1198, -0.0950],\n",
      "          [-0.0304, -0.0315,  0.0967, -0.0297],\n",
      "          [ 0.0692, -0.1252, -0.0929, -0.0483],\n",
      "          [ 0.0631,  0.1045, -0.0244, -0.0493]],\n",
      "\n",
      "         [[ 0.0494,  0.0723, -0.0519,  0.0014],\n",
      "          [-0.0068, -0.0452,  0.0789,  0.0938],\n",
      "          [-0.1046, -0.0022,  0.0069, -0.0415],\n",
      "          [-0.1134, -0.0927,  0.0048,  0.0249]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0533,  0.0018, -0.1011, -0.0924],\n",
      "          [ 0.0523, -0.0805, -0.0791,  0.0508],\n",
      "          [-0.0997, -0.1199,  0.1092, -0.0663],\n",
      "          [-0.0874, -0.0016, -0.0824, -0.0822]],\n",
      "\n",
      "         [[ 0.0368, -0.0033,  0.0615, -0.0006],\n",
      "          [-0.0038,  0.1248,  0.0514, -0.0860],\n",
      "          [-0.0858, -0.1217,  0.0893, -0.0678],\n",
      "          [-0.1166,  0.1021,  0.1070,  0.0314]],\n",
      "\n",
      "         [[-0.0191, -0.0289, -0.1088,  0.0123],\n",
      "          [-0.1191,  0.0675, -0.0309,  0.0553],\n",
      "          [ 0.0552, -0.0660,  0.0983,  0.0302],\n",
      "          [ 0.1083,  0.0174,  0.0611,  0.0990]],\n",
      "\n",
      "         [[-0.0638,  0.0058,  0.0253,  0.0377],\n",
      "          [ 0.0277, -0.0345,  0.0909, -0.0273],\n",
      "          [-0.1161, -0.0198, -0.0306,  0.0462],\n",
      "          [ 0.0074,  0.0834, -0.0947,  0.0021]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0548, -0.0588,  0.0197, -0.0524],\n",
      "          [ 0.0100,  0.0200, -0.0175, -0.0470],\n",
      "          [ 0.1138, -0.0317, -0.0708,  0.0883],\n",
      "          [-0.0546, -0.0386,  0.1202,  0.0470]],\n",
      "\n",
      "         [[-0.0047, -0.0798,  0.0554,  0.0187],\n",
      "          [ 0.1133, -0.0025, -0.0274, -0.0356],\n",
      "          [-0.0245, -0.1023, -0.0508,  0.1174],\n",
      "          [-0.0051,  0.0693, -0.0621,  0.1189]],\n",
      "\n",
      "         [[ 0.0906,  0.0984, -0.0535, -0.0085],\n",
      "          [ 0.0877, -0.0049, -0.0355,  0.1185],\n",
      "          [ 0.0564,  0.0589, -0.0661,  0.0478],\n",
      "          [ 0.1123,  0.0792,  0.1169,  0.0361]],\n",
      "\n",
      "         [[-0.0746, -0.0577,  0.0044,  0.0275],\n",
      "          [ 0.1056, -0.0765,  0.1198, -0.0065],\n",
      "          [ 0.0335, -0.0223, -0.1044,  0.0934],\n",
      "          [-0.0207,  0.1131,  0.0233,  0.0778]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 0.0036, -0.0715, -0.0179,  0.0079],\n",
      "          [-0.0992,  0.0160,  0.0129,  0.1036],\n",
      "          [-0.1153,  0.0189,  0.0292,  0.1138],\n",
      "          [-0.0414,  0.0947,  0.0218, -0.0739]],\n",
      "\n",
      "         [[ 0.1149,  0.0853,  0.0005, -0.0407],\n",
      "          [ 0.0664, -0.0066,  0.1175, -0.0791],\n",
      "          [ 0.0790,  0.0525, -0.0491,  0.0068],\n",
      "          [ 0.0462, -0.0209, -0.0417, -0.1028]],\n",
      "\n",
      "         [[-0.1298,  0.1044, -0.0952, -0.1209],\n",
      "          [-0.0551,  0.0487, -0.0351,  0.0769],\n",
      "          [-0.1128, -0.0947, -0.0981,  0.0827],\n",
      "          [ 0.1154,  0.0325, -0.0055,  0.0580]],\n",
      "\n",
      "         [[ 0.0657,  0.0697,  0.0943,  0.0188],\n",
      "          [-0.0679, -0.0862, -0.0791,  0.0965],\n",
      "          [-0.0132, -0.0407, -0.0272, -0.1064],\n",
      "          [-0.1212,  0.1010,  0.0050,  0.0801]]],\n",
      "\n",
      "\n",
      "        [[[-0.1131, -0.0539, -0.0402, -0.0970],\n",
      "          [-0.0571,  0.0428, -0.0179, -0.0066],\n",
      "          [ 0.1175,  0.0064,  0.0750,  0.0975],\n",
      "          [-0.1130,  0.0761,  0.0179, -0.1033]],\n",
      "\n",
      "         [[-0.0296,  0.0776, -0.1052,  0.0310],\n",
      "          [-0.1100, -0.1022,  0.0423,  0.0068],\n",
      "          [-0.0823, -0.0933, -0.1045,  0.0708],\n",
      "          [-0.0477, -0.0253,  0.0424,  0.1072]],\n",
      "\n",
      "         [[ 0.1074,  0.0711,  0.0011,  0.0687],\n",
      "          [-0.0125,  0.0578, -0.0898,  0.1020],\n",
      "          [-0.0875, -0.0676, -0.0017,  0.0602],\n",
      "          [ 0.1107, -0.0795,  0.0069, -0.0156]],\n",
      "\n",
      "         [[ 0.0270,  0.0482, -0.0540, -0.1107],\n",
      "          [-0.0033, -0.0627, -0.0585,  0.0037],\n",
      "          [-0.0152,  0.1165, -0.0562,  0.1349],\n",
      "          [ 0.1093, -0.0649,  0.0223, -0.0364]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0650, -0.0526, -0.0952, -0.0798],\n",
      "          [ 0.0019,  0.1114,  0.1185,  0.0197],\n",
      "          [ 0.0036,  0.0276,  0.0534,  0.0913],\n",
      "          [ 0.0534,  0.0383, -0.0186,  0.0660]],\n",
      "\n",
      "         [[-0.0605, -0.0573, -0.1328,  0.0757],\n",
      "          [-0.0374, -0.0212,  0.0551, -0.0709],\n",
      "          [-0.0189, -0.0608,  0.0310,  0.0671],\n",
      "          [ 0.0227, -0.0256, -0.1310, -0.0178]],\n",
      "\n",
      "         [[-0.1139, -0.1050, -0.1278, -0.0945],\n",
      "          [ 0.0661, -0.0838,  0.0292, -0.0051],\n",
      "          [-0.1111,  0.1030, -0.0794, -0.0477],\n",
      "          [-0.1160,  0.0522, -0.0909, -0.1057]],\n",
      "\n",
      "         [[ 0.0466, -0.0326, -0.1162, -0.1185],\n",
      "          [ 0.0413, -0.0683,  0.0232, -0.0227],\n",
      "          [-0.0851,  0.1067, -0.0796, -0.0623],\n",
      "          [-0.0340,  0.0267,  0.0290, -0.0387]]]], device='cuda:0',\n",
      "       requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "print(model.encoder[0][0].weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python torch",
   "language": "python",
   "name": "torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
