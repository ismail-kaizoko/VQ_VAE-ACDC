{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch \n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "import torch.optim as optim\n",
    "\n",
    "\n",
    "# Data preprocessing utils : \n",
    "from torchvision.transforms import Compose\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Visuals utils\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "# my defined model\n",
    "from utils.acdc_dataset import *\n",
    "from utils.funcs import *\n",
    "from utils.vqvae import *\n",
    "from utils.launcher_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import torch\n",
    "\n",
    "def load_model_from_metadata(json_filepath):\n",
    "    \"\"\"\n",
    "    Load model parameters from a JSON file and instantiate a new model.\n",
    "\n",
    "    Args:\n",
    "        json_filepath (str): Path to the JSON file containing the metadata.\n",
    "\n",
    "    Returns:\n",
    "        model: A new instance of the model with the saved parameters.\n",
    "    \"\"\"\n",
    "    # Load the JSON file\n",
    "    with open(json_filepath, 'r') as f:\n",
    "        metadata = json.load(f)\n",
    "\n",
    "    # Extract model parameters from the metadata\n",
    "    model_params = metadata.get(\"model_parameters\", {})\n",
    "    print(\"Loaded model parameters:\", model_params)\n",
    "\n",
    "    # Instantiate a new model with the extracted parameters\n",
    "    model = VQVAE(**model_params)\n",
    "\n",
    "    return model\n",
    "\n",
    "def shrink_model_from_metadata(json_filepath, new_K):\n",
    "    \"\"\"\n",
    "    Load model parameters from a JSON file and instantiate a new model.\n",
    "\n",
    "    Args:\n",
    "        json_filepath (str): Path to the JSON file containing the metadata.\n",
    "\n",
    "    Returns:\n",
    "        model: A new instance of the model with the saved parameters.\n",
    "    \"\"\"\n",
    "    # Load the JSON file\n",
    "    with open(json_filepath, 'r') as f:\n",
    "        metadata = json.load(f)\n",
    "\n",
    "    # Extract model parameters from the metadata\n",
    "    model_params = metadata.get(\"model_parameters\", {})\n",
    "\n",
    "    #reduce the size of K : \n",
    "    model_params['num_embeddings'] = new_K\n",
    "    print(\"Loaded model parameters:\", model_params)\n",
    "\n",
    "    # Instantiate a new model with the extracted parameters\n",
    "    model = VQVAE(**model_params)\n",
    "\n",
    "    return model\n",
    "\n",
    "# Example usage:\n",
    "# Assuming VQVAE is your model class\n",
    "# json_filepath = \"./training_metadata/training_metadata_20231025_123456.json\"\n",
    "# model2 = load_model_from_metadata(json_filepath, VQVAE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'embedding_dim': 64, 'num_embeddings': 512, 'downsampling_factor': 8, 'residual': False, 'num_quantizers': 2, 'shared_codebook': False, 'beta': 0.25, 'decay': 0.8, 'data_mod': 'SEG'}\n",
      "{'embedding_dim': 64, 'num_embeddings': 128, 'downsampling_factor': 8, 'residual': False, 'num_quantizers': 2, 'shared_codebook': False, 'beta': 0.25, 'decay': 0.8, 'data_mod': 'SEG'}\n"
     ]
    }
   ],
   "source": [
    "json_filepath = 'saved_models/seg/random.pth'.replace('.pth', '.json')\n",
    "with open(json_filepath, 'r') as f:\n",
    "    metadata = json.load(f)\n",
    "\n",
    "model_params = metadata.get(\"model_parameters\", {})\n",
    "\n",
    "print(model_params)\n",
    "new_K = 128\n",
    "#reduce the size of K : \n",
    "model_params['num_embeddings'] = new_K\n",
    "\n",
    "\n",
    "print(model_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model parameters: {'embedding_dim': 64, 'num_embeddings': 512, 'downsampling_factor': 8, 'residual': False, 'num_quantizers': 2, 'shared_codebook': False, 'beta': 0.25, 'decay': 0.8, 'data_mod': 'SEG'}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "baseline_model_path = 'saved_models/seg/random.pth'\n",
    "baseline_model_metdat = (baseline_model_path).replace('.pth', '.json')\n",
    "baseline_model = load_model_from_metadata(baseline_model_metdat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1420646/2651044302.py:4: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(baseline_model_path)\n"
     ]
    }
   ],
   "source": [
    "# saving the previous model encoder and decoder : \n",
    "\n",
    "# Load the saved model checkpoint\n",
    "checkpoint = torch.load(baseline_model_path)\n",
    "# Filter the encoder parameters\n",
    "encoder_state_dict = {k: v for k, v in checkpoint['model_state_dict'].items() if k.startswith('encoder.')}\n",
    "# Filter the decoder parameters\n",
    "decoder_state_dict = {k: v for k, v in checkpoint['model_state_dict'].items() if k.startswith('decoder.')}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_params = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we are going to pass through the whole dataset, which results on \n",
    "\n",
    "latent_vectors = []\n",
    "\n",
    "# Process the dataset\n",
    "with torch.no_grad():  # No need to track gradients\n",
    "    for batch in TrainLoader:\n",
    "        # Pass the batch through the encoder\n",
    "        encoded = model.encode(batch.float().to(device))[0]  # Output shape: (batch_size, 32, 32, 32)\n",
    "        \n",
    "        # Flatten the encoded output to (batch_size, 32*32)\n",
    "        encoded_flat = encoded.view(encoded.size(0), 64, -1).permute(0, 2, 1)  # Shape: (batch_size, 1024, 64)\n",
    "        \n",
    "        # Now flatten across the batch and spatial dimensions to (batch_size * 1024, 64)\n",
    "        encoded_flat = encoded_flat.reshape(-1, 64)\n",
    "        \n",
    "        # Convert the tensor to NumPy and store it\n",
    "        latent_vectors.append(encoded_flat.cpu().numpy())\n",
    "\n",
    "# Concatenate all the latent vectors into a single NumPy array\n",
    "latent_vectors = np.concatenate(latent_vectors, axis=0)  # Shape: (size_of_dataset, 32*32)\n",
    "\n",
    "# # Optionally, save the latent vectors to disk\n",
    "# np.save('latent_vectors.npy', latent_vectors)\n",
    "\n",
    "new_codebook = torch.from_numpy(centers_init)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python torch",
   "language": "python",
   "name": "torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
