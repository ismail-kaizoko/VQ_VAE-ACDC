{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch \n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "import torch.optim as optim\n",
    "\n",
    "\n",
    "# Data preprocessing utils : \n",
    "from torchvision.transforms import Compose\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Visuals utils\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "# my defined model\n",
    "from utils.acdc_dataset import *\n",
    "from utils.funcs import *\n",
    "from utils.vqvae import *\n",
    "from utils.launcher_utils import *\n",
    "\n",
    "import json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_mod = 'SEG'\n",
    "L = 128\n",
    "batch_size = 16\n",
    "\n",
    "#################### dataset init ######################\n",
    "dataset_path = \"/home/ids/ihamdaoui-21/ACDC/database\"\n",
    "\n",
    "train_set_path = os.path.join(dataset_path, \"training\")\n",
    "test_set_path  = os.path.join(dataset_path, \"testing\")\n",
    "\n",
    "\n",
    "train_dataset = load_dataset(train_set_path, modality= data_mod)\n",
    "test_dataset  = load_dataset(test_set_path, modality= data_mod)\n",
    "\n",
    "\n",
    "if data_mod == 'SEG':\n",
    "    input_transforms = Compose([\n",
    "        transforms.Resize(size=(L,L), interpolation=transforms.InterpolationMode.NEAREST),\n",
    "        One_hot_Transform(num_classes=4)\n",
    "        ])\n",
    "else : \n",
    "    input_transforms = Compose([\n",
    "        transforms.Resize(size=(L,L), interpolation=transforms.InterpolationMode.NEAREST),\n",
    "        PercentileClip(lower_percentile=1, upper_percentile=99),\n",
    "        MinMaxNormalize(min_value=0.0, max_value=1.0),\n",
    "        ])\n",
    "\n",
    "\n",
    "TrainDataset = ACDC_Dataset(data = train_dataset, transforms= input_transforms) \n",
    "TestDataset  = ACDC_Dataset(data = test_dataset, transforms= input_transforms)\n",
    "\n",
    "TrainLoader  = DataLoader(TrainDataset, batch_size = batch_size, shuffle = True)\n",
    "TestLoader   = DataLoader(TestDataset , batch_size = batch_size, shuffle = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'embedding_dim': 64, 'num_embeddings': 512, 'downsampling_factor': 8, 'residual': False, 'num_quantizers': 2, 'shared_codebook': False, 'beta': 0.25, 'decay': 0.8, 'data_mod': 'SEG', 'loss_func': None}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "baseline_model_path = 'saved_models/seg/301.pth'\n",
    "baseline_model_params = load_model_metadata(baseline_model_path)\n",
    "baseline_model = VQVAE(**baseline_model_params).to(device)\n",
    "print(baseline_model_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_757967/2651044302.py:4: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(baseline_model_path)\n"
     ]
    }
   ],
   "source": [
    "# saving the previous model encoder and decoder : \n",
    "\n",
    "# Load the saved model checkpoint\n",
    "checkpoint = torch.load(baseline_model_path)\n",
    "# Filter the encoder parameters\n",
    "encoder_state_dict = {k: v for k, v in checkpoint['model_state_dict'].items() if k.startswith('encoder.')}\n",
    "# Filter the decoder parameters\n",
    "decoder_state_dict = {k: v for k, v in checkpoint['model_state_dict'].items() if k.startswith('decoder.')}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'embedding_dim': 64, 'num_embeddings': 256, 'downsampling_factor': 8, 'residual': False, 'num_quantizers': 2, 'shared_codebook': False, 'beta': 0.25, 'decay': 0.8, 'data_mod': 'SEG', 'loss_func': None}\n",
      "{'embedding_dim': 64, 'num_embeddings': 512, 'downsampling_factor': 8, 'residual': False, 'num_quantizers': 2, 'shared_codebook': False, 'beta': 0.25, 'decay': 0.8, 'data_mod': 'SEG', 'loss_func': None}\n"
     ]
    }
   ],
   "source": [
    "new_K = 256\n",
    "model_params = baseline_model_params.copy()\n",
    "model_params['num_embeddings'] = new_K\n",
    "print(model_params)\n",
    "print(baseline_model_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = VQVAE(**model_params).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 4.9095e-02,  4.4974e-02,  4.4974e-02,  ...,  4.7980e-02,\n",
      "          4.7980e-02,  4.7943e-02],\n",
      "        [ 1.1339e-03, -3.1888e-06, -3.1835e-06,  ..., -1.6194e-04,\n",
      "         -1.7578e-04, -1.6076e-04],\n",
      "        [ 1.8823e-02,  1.7054e-02,  1.7182e-02,  ...,  2.0055e-02,\n",
      "          2.2020e-02,  2.0360e-02],\n",
      "        ...,\n",
      "        [ 4.3589e-02,  4.3720e-02,  4.4053e-02,  ...,  3.6490e-02,\n",
      "          3.5010e-02,  3.6336e-02],\n",
      "        [ 1.3915e-02,  1.3861e-02,  1.3861e-02,  ...,  9.0801e-03,\n",
      "          9.0801e-03,  5.7537e-03],\n",
      "        [ 2.2129e-02,  2.2066e-02,  2.1970e-02,  ...,  3.5239e-02,\n",
      "          3.4859e-02,  3.0908e-02]])\n"
     ]
    }
   ],
   "source": [
    "# we are going to pass through the whole dataset, which results on \n",
    "\n",
    "latent_vectors = []\n",
    "\n",
    "# Process the dataset\n",
    "with torch.no_grad():  # No need to track gradients\n",
    "    for batch in TrainLoader:\n",
    "        # Pass the batch through the encoder\n",
    "        encoded = baseline_model.encode(batch.float().to(device))[0]  # Output shape: (batch_size, 32, 32, 32)\n",
    "        \n",
    "        # Flatten the encoded output to (batch_size, 32*32)\n",
    "        encoded_flat = encoded.view(encoded.size(0), 64, -1).permute(0, 2, 1)  # Shape: (batch_size, 1024, 64)\n",
    "        \n",
    "        # Now flatten across the batch and spatial dimensions to (batch_size * 1024, 64)\n",
    "        encoded_flat = encoded_flat.reshape(-1, 64)\n",
    "        \n",
    "        # Convert the tensor to NumPy and store it\n",
    "        latent_vectors.append(encoded_flat.cpu().numpy())\n",
    "\n",
    "# Concatenate all the latent vectors into a single NumPy array\n",
    "latent_vectors = np.concatenate(latent_vectors, axis=0)  # Shape: (size_of_dataset, 32*32)\n",
    "\n",
    "# # Optionally, save the latent vectors to disk\n",
    "# np.save('latent_vectors.npy', latent_vectors)\n",
    "from sklearn.cluster import kmeans_plusplus\n",
    "\n",
    "# Calculate seeds from k-means++\n",
    "centers_init, indices = kmeans_plusplus(latent_vectors, n_clusters= new_K)\n",
    "\n",
    "new_codebook = torch.from_numpy(centers_init)\n",
    "print(new_codebook)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the encoder and decoder weights into the new model\n",
    "# Remove the 'encoder.' prefix from all keys in encoder_state_dict\n",
    "encoder_state_dict = {k.replace('encoder.', ''): v for k, v in encoder_state_dict.items()}\n",
    "model.encoder.load_state_dict(encoder_state_dict)\n",
    "\n",
    "# Remove the 'encoder.' prefix from all keys in encoder_state_dict\n",
    "decoder_state_dict = {k.replace('decoder.', ''): v for k, v in decoder_state_dict.items()}\n",
    "model.decoder.load_state_dict(decoder_state_dict)\n",
    "\n",
    "model.vq_layer.codebook = new_codebook\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"saved_models/Refit/445.pth\"\n",
    "lr = 5e-4\n",
    "epochs = 40\n",
    "optimizer = optim.AdamW(model.parameters(), lr=lr, weight_decay=1e-4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/119 [00:00<?, ?batch/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 119/119 [00:09<00:00, 12.85batch/s, loss=0.0287]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 119/119 [00:04<00:00, 25.07batch/s, loss=0.0282]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 119/119 [00:04<00:00, 27.85batch/s, loss=0.0212]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 119/119 [00:06<00:00, 17.73batch/s, loss=0.021] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 119/119 [00:04<00:00, 27.54batch/s, loss=0.0249]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 119/119 [00:04<00:00, 25.74batch/s, loss=0.0261]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 119/119 [00:07<00:00, 15.12batch/s, loss=0.0284]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 119/119 [00:11<00:00, 10.41batch/s, loss=0.0201]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 119/119 [00:06<00:00, 18.89batch/s, loss=0.0199]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 119/119 [00:05<00:00, 21.89batch/s, loss=0.026] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 119/119 [00:06<00:00, 17.80batch/s, loss=0.0284]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 119/119 [00:05<00:00, 22.76batch/s, loss=0.0241]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 119/119 [00:08<00:00, 14.37batch/s, loss=0.0179]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 119/119 [00:07<00:00, 15.04batch/s, loss=0.0258]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 119/119 [00:05<00:00, 20.76batch/s, loss=0.0222]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 119/119 [00:05<00:00, 20.73batch/s, loss=0.0253]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 119/119 [00:07<00:00, 16.41batch/s, loss=0.0263]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 119/119 [00:05<00:00, 20.18batch/s, loss=0.0278]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 119/119 [00:05<00:00, 22.87batch/s, loss=0.0224]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 119/119 [00:04<00:00, 25.80batch/s, loss=0.0241]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 119/119 [00:04<00:00, 25.74batch/s, loss=0.0218]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 119/119 [00:07<00:00, 15.54batch/s, loss=0.0268]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 119/119 [00:05<00:00, 22.38batch/s, loss=0.0224]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 119/119 [00:06<00:00, 17.51batch/s, loss=0.0251]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 119/119 [00:04<00:00, 24.33batch/s, loss=0.0251]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 119/119 [00:07<00:00, 15.57batch/s, loss=0.0211]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 119/119 [00:08<00:00, 14.59batch/s, loss=0.0236]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 119/119 [00:05<00:00, 23.67batch/s, loss=0.0218]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 119/119 [00:15<00:00,  7.46batch/s, loss=0.0239]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 119/119 [00:07<00:00, 15.39batch/s, loss=0.0212]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 119/119 [00:09<00:00, 12.12batch/s, loss=0.023] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 119/119 [00:11<00:00, 10.64batch/s, loss=0.0288]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 119/119 [00:06<00:00, 19.44batch/s, loss=0.0239]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 119/119 [00:09<00:00, 11.94batch/s, loss=0.023] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 119/119 [00:05<00:00, 23.24batch/s, loss=0.021] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 119/119 [00:07<00:00, 16.59batch/s, loss=0.0252]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 119/119 [00:06<00:00, 17.81batch/s, loss=0.0231]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 119/119 [00:04<00:00, 23.84batch/s, loss=0.0176]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 119/119 [00:06<00:00, 19.38batch/s, loss=0.0201]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 119/119 [00:06<00:00, 18.39batch/s, loss=0.0206]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39: \n",
      "Training complete.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model.train()\n",
    "\n",
    "train_loss_values    = []\n",
    "commit_loss_values   = []\n",
    "val_loss_values      = []\n",
    "\n",
    "\n",
    "best_val_loss = float('inf')\n",
    "\n",
    "for epoch in range(epochs):\n",
    "\n",
    "    train_loss  = []\n",
    "    commit_loss = []\n",
    "\n",
    "    with tqdm(enumerate(TrainLoader), unit=\"batch\", total=len(TrainLoader)) as tepoch:\n",
    "        for batch_idx, (inputs) in tepoch:\n",
    "            inputs = inputs.float().to(device)  # Move data to the appropriate device (GPU/CPU)\n",
    "            \n",
    "            # Zero gradients\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # Forward pass // args is a list containing : [output, input, vq_loss]\n",
    "            output, inputs, indices, commitement_Loss = model(inputs)\n",
    "            \n",
    "            # Loss and backward\n",
    "            all_loss = model.loss_function(output, inputs, indices, commitement_Loss)\n",
    "            loss = all_loss['loss']  # Use the loss function defined in the model\n",
    "            recons_loss = all_loss['Reconstruction_Loss']\n",
    "            commitement_Loss = all_loss['commitement_Loss']\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "                        \n",
    "            # Track running loss\n",
    "            train_loss.append( recons_loss.item() )\n",
    "            commit_loss.append( commitement_Loss.item() )\n",
    "\n",
    "            # tqdm bar displays the loss\n",
    "            tepoch.set_postfix(loss=loss.item())\n",
    "\n",
    "    train_loss_values.append( np.mean(train_loss))\n",
    "    commit_loss_values.append( np.mean(commit_loss))\n",
    "\n",
    "    # Validation after each epoch\n",
    "    val_loss = evaluate_model(model, TestLoader, device)\n",
    "    val_loss_values.append(val_loss)\n",
    "\n",
    "    #saving model if Loss values decreases\n",
    "    if val_loss < best_val_loss :\n",
    "        save_model(model_name, model, epoch, train_loss_values, val_loss_values, commit_loss_values, val_loss)\n",
    "        best_val_loss = val_loss\n",
    "\n",
    "    print('Epoch {}: '.format(epoch))\n",
    "\n",
    "\n",
    "print(\"Training complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9633495632339927\n"
     ]
    }
   ],
   "source": [
    "print(score_model(model, TestLoader, device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ONLY 85 OF CODES WERE USED FROM 256, WHICH MAKE 33.203125 % OF CODES FROM THE CODE-BOOK\n"
     ]
    }
   ],
   "source": [
    "hist, percentage = codebook_hist_testset(model, TestLoader, device)\n",
    "hist = hist/np.sum(hist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python torch",
   "language": "python",
   "name": "torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
